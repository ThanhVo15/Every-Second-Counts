{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9823351b",
   "metadata": {},
   "source": [
    "# 19/10/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a9733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Tên bài:** Phân loại Độ dài Chuỗi Dữ liệu\n",
    "\n",
    "# ### 🎯 Mục tiêu\n",
    "\n",
    "# Trong phân tích văn bản (NLP/AI), việc biết độ dài của dữ liệu đầu vào là rất quan trọng. \n",
    "# Hãy viết một hàm Python nhận vào một danh sách các chuỗi (giả định là các đoạn văn bản) và trả về một **từ điển** (dictionary) \n",
    "# tóm tắt **số lần xuất hiện** của các độ dài chuỗi đó.\n",
    "\n",
    "# ### 📜 Yêu cầu\n",
    "\n",
    "# 1.  Viết hàm `count_string_lengths(data: list[str]) -> dict[int, int]`.\n",
    "# 2.  Hàm nhận vào một danh sách các chuỗi (`data`).\n",
    "# 3.  Đối với mỗi chuỗi, tính độ dài của nó.\n",
    "# 4.  Đếm số lần mỗi độ dài chuỗi xuất hiện trong danh sách.\n",
    "# 5.  Trả về một từ điển trong đó:\n",
    "#       * **Khóa** là độ dài chuỗi (số nguyên).\n",
    "#       * **Giá trị** là số lần độ dài đó xuất hiện (số nguyên).\n",
    "\n",
    "# ### 📝 Ví dụ\n",
    "\n",
    "# | Input (`data`) | Output (Từ điển) | Giải thích |\n",
    "# | :--- | :--- | :--- |\n",
    "# | `[\"AI\", \"Data\", \"Science\", \"ML\", \"Model\"]` | `{2: 2, 4: 1, 7: 1, 5: 1}` | \"AI\", \"ML\" có độ dài 2 (2 lần); \"Data\" độ dài 4 (1 lần); \"Science\" độ dài 7 (1 lần); \"Model\" độ dài 5 (1 lần). |\n",
    "# | `[\"\", \"A\", \"BB\", \"A\"]` | `{0: 1, 1: 2, 2: 1}` | Chuỗi rỗng độ dài 0 (1 lần); \"A\" độ dài 1 (2 lần); \"BB\" độ dài 2 (1 lần). |\n",
    "\n",
    "# # Kiểm tra\n",
    "# test_data_1 = [\"AI\", \"Data\", \"Science\", \"ML\", \"Model\"]\n",
    "# print(f\"Input: {test_data_1}\")\n",
    "# print(f\"Output: {count_string_lengths(test_data_1)}\")\n",
    "\n",
    "# test_data_2 = [\"\", \"A\", \"BB\", \"A\"]\n",
    "# print(f\"Input: {test_data_2}\")\n",
    "# print(f\"Output: {count_string_lengths(test_data_2)}\")\n",
    "# ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b245514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ['AI', 'Data', 'Science', 'ML', 'Model']\n",
      "Output: {2: 2, 4: 1, 7: 1, 5: 1}\n",
      "Input: ['', 'A', 'BB', 'A']\n",
      "Output: {0: 1, 1: 2, 2: 1}\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "def count_string_lengths(data: List[str]) -> List[str]:\n",
    "    result = defaultdict(int)\n",
    "\n",
    "    for word in data:\n",
    "        length = len(word)\n",
    "\n",
    "        result[length] +=1\n",
    "    return dict(result)\n",
    "        \n",
    "\n",
    "# # Kiểm tra\n",
    "test_data_1 = [\"AI\", \"Data\", \"Science\", \"ML\", \"Model\"]\n",
    "print(f\"Input: {test_data_1}\")\n",
    "print(f\"Output: {count_string_lengths(test_data_1)}\")\n",
    "\n",
    "test_data_2 = [\"\", \"A\", \"BB\", \"A\"]\n",
    "print(f\"Input: {test_data_2}\")\n",
    "print(f\"Output: {count_string_lengths(test_data_2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d864511b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter({'A': 1, 'I': 1}),\n",
       " Counter({'a': 2, 'D': 1, 't': 1}),\n",
       " Counter({'c': 2, 'e': 2, 'S': 1, 'i': 1, 'n': 1}),\n",
       " Counter({'M': 1, 'L': 1}),\n",
       " Counter({'M': 1, 'o': 1, 'd': 1, 'e': 1, 'l': 1})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_1 = [\"AI\", \"Data\", \"Science\", \"ML\", \"Model\"]\n",
    "result = []\n",
    "for word in test_data_1:\n",
    "    c = Counter(word)\n",
    "    result.append(c)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab05947",
   "metadata": {},
   "source": [
    "# 20/10/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca52d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# **Tập trung vào:** Phân tích dữ liệu, Xử lý chuỗi, Tư duy logic cho việc tiền xử lý dữ liệu (Pre-processing) trong AI/ML.\n",
    "\n",
    "# ### Tên bài toán: Phân Tích Cảm Xúc Cơ Bản (Basic Sentiment Analysis)\n",
    "\n",
    "# ### Mô tả\n",
    "\n",
    "# Trong lĩnh vực Xử lý Ngôn ngữ Tự nhiên (NLP), việc trích xuất cảm xúc từ văn bản là bước quan trọng. \n",
    "# Bạn được cung cấp một **danh sách các câu** (ví dụ: bình luận, đánh giá). \n",
    "# Nhiệm vụ của bạn là viết một hàm Python để phân loại mỗi câu thành \n",
    "# **Tích Cực** (Positive), **Tiêu Cực** (Negative) hoặc **Trung Tính** (Neutral) dựa trên sự xuất hiện của các từ khóa.\n",
    "\n",
    "# ### Yêu cầu\n",
    "\n",
    "# Viết một hàm Python `analyze_sentiment(sentences)` nhận vào một danh sách các chuỗi (câu) và\n",
    "#  trả về một danh sách các chuỗi kết quả ('Tích Cực', 'Tiêu Cực', hoặc 'Trung Tính').\n",
    "\n",
    "# **Các quy tắc phân loại:**\n",
    "\n",
    "# 1.  **Tích Cực** nếu câu chứa ít nhất một trong các từ khóa: **'great', 'excellent', 'love', 'amazing'**.\n",
    "# 2.  **Tiêu Cực** nếu câu chứa ít nhất một trong các từ khóa: **'bad', 'worst', 'poor', 'disappointed'**.\n",
    "# 3.  **Trung Tính** nếu câu không chứa từ khóa Tích Cực hay Tiêu Cực nào.\n",
    "# 4.  ***Lưu ý:*** **Ưu tiên Tích Cực** hơn Tiêu Cực nếu một câu chứa cả từ khóa Tích Cực và Tiêu Cực.\n",
    "# 5.  Việc kiểm tra **không phân biệt chữ hoa, chữ thường** (case-insensitive).\n",
    "\n",
    "# ### Ví dụ\n",
    "\n",
    "# | Input (sentences) | Output (sentiment results) | Giải thích |\n",
    "# | :--- | :--- | :--- |\n",
    "# | `[\"This is a great product.\"]` | `['Tích Cực']` | Chứa từ 'great'. |\n",
    "# | `[\"The service was bad.\"]` | `['Tiêu Cực']` | Chứa từ 'bad'. |\n",
    "# | `[\"It was okay, not good.\"]` | `['Trung Tính']` | Không chứa từ khóa nào. |\n",
    "# | `[\"The quality was great but the price was bad.\"]` | `['Tích Cực']` | Chứa cả 'great' và 'bad', ưu tiên Tích Cực. |\n",
    "\n",
    "# ### Lời giải (Ẩn)\n",
    "\n",
    "# ```python\n",
    "# def analyze_sentiment(sentences):\n",
    "#     \"\"\"\n",
    "#     Phân loại cảm xúc cơ bản cho một danh sách các câu.\n",
    "#     Ưu tiên Tích Cực hơn Tiêu Cực.\n",
    "#     \"\"\"\n",
    "#     positive_words = {'great', 'excellent', 'love', 'amazing'}\n",
    "#     negative_words = {'bad', 'worst', 'poor', 'disappointed'}\n",
    "#     results = []\n",
    "\n",
    "#     for sentence in sentences:\n",
    "#         # Chuyển câu thành chữ thường để kiểm tra không phân biệt chữ hoa, chữ thường\n",
    "#         sentence_lower = sentence.lower()\n",
    "\n",
    "#         # Kiểm tra sự xuất hiện của từ khóa\n",
    "#         is_positive = any(word in sentence_lower for word in positive_words)\n",
    "#         is_negative = any(word in sentence_lower for word in negative_words)\n",
    "\n",
    "#         # Áp dụng quy tắc phân loại (Ưu tiên Tích Cực)\n",
    "#         if is_positive:\n",
    "#             results.append('Tích Cực')\n",
    "#         elif is_negative:\n",
    "#             results.append('Tiêu Cực')\n",
    "#         else:\n",
    "#             results.append('Trung Tính')\n",
    "\n",
    "#     return results\n",
    "\n",
    "# # Ví dụ kiểm tra:\n",
    "# test_sentences = [\n",
    "#     \"This is a great product.\",\n",
    "#     \"The service was bad.\",\n",
    "#     \"It was okay, not good.\",\n",
    "#     \"The quality was great but the price was bad.\",\n",
    "#     \"Nothing special here.\"\n",
    "# ]\n",
    "\n",
    "# # print(analyze_sentiment(test_sentences))\n",
    "# # Kết quả mong đợi: ['Tích Cực', 'Tiêu Cực', 'Trung Tính', 'Tích Cực', 'Trung Tính']\n",
    "# ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0136884b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive', 'Netral', 'Negative', 'Positive', 'Negative']\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "def analyze_sentiment(sentences: List[str]) -> List[str]:\n",
    "    positive_words = {'great', 'excellent', 'love', 'amazing'}\n",
    "    negative_words = {'bad', 'worst', 'poor', 'disappointed'}\n",
    "    results = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_lower = sentence.lower()\n",
    "\n",
    "        is_positive = any(word in sentence_lower for word in positive_words)\n",
    "        is_negative = any(word in sentence_lower for word in negative_words)\n",
    "\n",
    "        if is_positive == True:\n",
    "            results.append(\"Positive\")\n",
    "        elif is_negative == False:\n",
    "            results.append(\"Negative\")\n",
    "        else:\n",
    "            results.append(\"Netral\")\n",
    "\n",
    "    return results\n",
    "        \n",
    "\n",
    "\n",
    "test_sentences = [\n",
    "    \"This is a great product.\",\n",
    "    \"The service was bad.\",\n",
    "    \"It was okay, not good.\",\n",
    "    \"The quality was great but the price was bad.\",\n",
    "    \"Nothing special here.\"\n",
    "]\n",
    "\n",
    "print(analyze_sentiment(test_sentences))\n",
    "# Kết quả mong đợi: ['Tích Cực', 'Tiêu Cực', 'Trung Tính', 'Tích Cực', 'Trung Tính']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb86f215",
   "metadata": {},
   "source": [
    "# 21/10/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36214367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 🎯 Mục tiêu\n",
    "\n",
    "# Luyện tập kỹ năng **xử lý chuỗi (string manipulation)** và **tính toán tần suất (frequency counting)**, \n",
    "# một kỹ năng cơ bản trong **Tiền xử lý Dữ liệu (Data Preprocessing)** và **Xử lý Ngôn ngữ Tự nhiên (NLP)**.\n",
    "\n",
    "# ### 📜 Yêu cầu Bài toán: Tìm Từ Đơn Độc\n",
    "\n",
    "# Cho một danh sách các câu (một mảng chuỗi), hãy tìm ra **tất cả các từ** chỉ xuất hiện **đúng một lần** trên *toàn bộ* danh sách câu đó. \n",
    "# Các từ không phân biệt chữ hoa/chữ thường.\n",
    "\n",
    "# **Ví dụ:**\n",
    "\n",
    "#   * **Đầu vào:** `sentences = [\"The cat sat on the mat.\", \"A dog chased the cat.\", \"The bird flew.\"]`\n",
    "\n",
    "#   * **Đầu ra Mong muốn (Danh sách các từ):** `[\"sat\", \"on\", \"mat\", \"a\", \"dog\", \"chased\", \"bird\", \"flew\"]`\n",
    "\n",
    "#   * **Giải thích:**\n",
    "\n",
    "#       * \"the\" và \"cat\" xuất hiện nhiều hơn một lần.\n",
    "#       * \"sat\", \"on\", \"mat\", \"a\", \"dog\", \"chased\", \"bird\", \"flew\" mỗi từ chỉ xuất hiện đúng một lần.\n",
    "\n",
    "# ### 🛠️ Hàm Cần Triển khai\n",
    "\n",
    "# ```python\n",
    "# def find_unique_words(sentences: list[str]) -> list[str]:\n",
    "#     \"\"\"\n",
    "#     Tìm tất cả các từ chỉ xuất hiện đúng một lần trong toàn bộ danh sách câu.\n",
    "    \n",
    "#     :param sentences: Danh sách các chuỗi câu.\n",
    "#     :return: Danh sách các từ đơn độc.\n",
    "#     \"\"\"\n",
    "#     pass\n",
    "# ```\n",
    "\n",
    "# ### 💡 Gợi ý\n",
    "\n",
    "# 1.  Cần phải chuẩn hóa tất cả các từ về **chữ thường**.\n",
    "# 2.  Loại bỏ các **dấu câu** (ví dụ: `.`, `,`).\n",
    "# 3.  Sử dụng một **từ điển (dictionary)** hoặc **`collections.Counter`** để đếm tần suất của mỗi từ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9b1653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sat', 'on', 'mat', 'a', 'dog', 'chased', 'bird', 'flew']\n"
     ]
    }
   ],
   "source": [
    "# from typing import List\n",
    "# from collections import Counter\n",
    "# import string\n",
    "\n",
    "# def find_unique_words(sentences: List[str]) -> List[str]:\n",
    "#     all_words = []\n",
    "\n",
    "#     for sentence in sentences:\n",
    "#         sentence_lower = sentence.lower()\n",
    "#         sentence_clean = sentence_lower.translate(str.maketrans('', '', string.punctuation))\n",
    "#         words = sentence_clean.split()\n",
    "#         all_words.extend(words)\n",
    "\n",
    "#     word_counts = Counter(all_words)\n",
    "#     result = [word for word, count in word_counts.items() if count == 1]\n",
    "\n",
    "#     return result\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     sentences = [\"The cat sat on the mat.\", \"A dog chased the cat.\", \"The bird flew.\"]\n",
    "#     result = find_unique_words(sentences)\n",
    "#     print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e89afd",
   "metadata": {},
   "source": [
    "# 22/10/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371377f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 📊 Ngữ cảnh & Mục tiêu: Chuẩn hóa Dữ liệu (Normalization)\n",
    "\n",
    "# Trong tiền xử lý dữ liệu cho Machine Learning/AI, **Chuẩn hóa Min-Max (Min-Max Normalization)** \n",
    "# là một kỹ thuật phổ biến để chuyển đổi các đặc trưng (features) về một phạm vi cố định, \n",
    "# thường là $[0, 1]$. Điều này giúp các thuật toán học (đặc biệt là các thuật toán dựa trên khoảng cách như K-Means, KNN) \n",
    "# hoạt động hiệu quả hơn và ngăn chặn các đặc trưng có phạm vi lớn chi phối.\n",
    "\n",
    "# **Yêu cầu:**\n",
    "\n",
    "# Viết một hàm Python có tên `min_max_normalize` nhận vào một **danh sách các số nguyên hoặc số thực (list of numbers)** \n",
    "# và trả về một **danh sách mới** chứa các giá trị đã được chuẩn hóa theo công thức sau:\n",
    "\n",
    "# $$\n",
    "# X_{\\text{norm}} = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}}\n",
    "# $$\n",
    "\n",
    "# Trong đó:\n",
    "# * $X$ là giá trị gốc.\n",
    "# * $X_{\\text{min}}$ là giá trị nhỏ nhất trong danh sách.\n",
    "# * $X_{\\text{max}}$ là giá trị lớn nhất trong danh sách.\n",
    "\n",
    "# **Lưu ý quan trọng:**\n",
    "# * Phải xử lý trường hợp đặc biệt: Nếu $X_{\\text{max}} = X_{\\text{min}}$ (tất cả các số đều bằng nhau), \n",
    "# hàm nên trả về một danh sách các số $0.0$ có cùng độ dài.\n",
    "# * Kết quả phải là danh sách các số thực (float).\n",
    "\n",
    "# ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78772dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [10, 20, 30, 40, 50] -> Output: [0.0, 0.25, 0.5, 0.75, 1.0]\n",
      "Input: [5, 5, 5, 5] -> Output: [0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Union\n",
    "\n",
    "def min_max_normalize(data: List[Union[int, float]]) -> List[float]:\n",
    "    \"\"\"\n",
    "    Chuẩn hóa Min-Max một danh sách các số về khoảng [0, 1].\n",
    "\n",
    "    Args:\n",
    "        data: Danh sách các số (int hoặc float).\n",
    "\n",
    "    Returns:\n",
    "        Danh sách các số đã được chuẩn hóa.\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        return []\n",
    "\n",
    "    max_x = max(data)\n",
    "    min_x = min(data)\n",
    "\n",
    "    # Xử lý trường hợp tất cả các phần tử bằng nhau\n",
    "    if min_x == max_x:\n",
    "        return [0.0] * len(data)  # Trả về list các số float 0.0\n",
    "    \n",
    "    # Sử dụng list comprehension cho ngắn gọn và hiệu quả\n",
    "    return [(x - min_x) / (max_x - min_x) for x in data]\n",
    "\n",
    "# Kiểm tra\n",
    "data1 = [10, 20, 30, 40, 50]\n",
    "print(f\"Input: {data1} -> Output: {min_max_normalize(data1)}\")\n",
    "\n",
    "data2 = [5, 5, 5, 5]\n",
    "print(f\"Input: {data2} -> Output: {min_max_normalize(data2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7700cddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.3333333333333333, 0.6666666666666666, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Input 1\n",
    "data1 = [10, 20, 30, 40, 50]\n",
    "# Expected Output: [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "# (Min=10, Max=50 -> Denominator=40. (10-10)/40=0.0, (20-10)/40=0.25, ...)\n",
    "\n",
    "\n",
    "# Input 2\n",
    "data2 = [5, 5, 5, 5]\n",
    "# Expected Output: [0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "\n",
    "# Input 3\n",
    "data3 = [-5, 0, 5, 10]\n",
    "# Expected Output: [0.0, 0.3333333333333333, 0.6666666666666666, 1.0]\n",
    "data1_res = min_max_normalize(data3)\n",
    "print(data1_res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
